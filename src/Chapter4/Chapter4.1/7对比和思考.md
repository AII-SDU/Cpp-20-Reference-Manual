# 对比和思考

本节分别使用 **rocBLAS** 和 **hipBLAS** 来进行矩阵乘法运算。

它们都通过矩阵乘法 `sgemm`（即单精度通用矩阵乘法）来测试 GPU 的性能和正确性。两者的操作流程几乎相同，包括：

1. 初始化矩阵A和B；
2. 将矩阵数据从主机内存复制到设备内存（GPU）；
3. 调用相应的BLAS库（rocBLAS或hipBLAS）的 `sgemm` 函数执行矩阵乘法运算；
4. 记录时间并计算性能（GFLOP/s）；
5. 将结果从设备内存复制回主机内存，并检查计算的正确性。

**rocBLAS** 示例代码如下：

```
#include <stdio.h>
#include <assert.h>
#include <hip/hip_runtime.h>
#include <rocblas/rocblas.h>

void ConstantInit(float *data, int size, float val) {
    for (int i = 0; i < size; ++i) {
        data[i] = val;
    }
}

/**
 * Run a simple test of matrix multiplication using rocBLAS
 */
int MatrixMultiply(int argc, char **argv, const dim3 &dimsA, const dim3 &dimsB) {
    // Allocate host memory for matrices A and B
    unsigned int size_A = dimsA.x * dimsA.y;
    unsigned int mem_size_A = sizeof(float) * size_A;
    float *h_A = (float*)malloc(mem_size_A);
    unsigned int size_B = dimsB.x * dimsB.y;
    unsigned int mem_size_B = sizeof(float) * size_B;
    float *h_B = (float*)malloc(mem_size_B);

    // Initialize host memory
    const float valB = 0.01f;
    ConstantInit(h_A, size_A, 1.0f);
    ConstantInit(h_B, size_B, valB);

    // Allocate device memory
    float *d_A, *d_B, *d_C;
    dim3 dimsC(dimsB.x, dimsA.y, 1);
    unsigned int mem_size_C = dimsC.x * dimsC.y * sizeof(float);
    float *h_C = (float*)malloc(mem_size_C);

    if (h_C == NULL) {
        fprintf(stderr, "Failed to allocate host matrix C!\n");
        exit(EXIT_FAILURE);
    }

    hipMalloc(&d_A, mem_size_A);
    hipMalloc(&d_B, mem_size_B);
    hipMalloc(&d_C, mem_size_C);

    // Allocate HIP events for timing
    hipEvent_t start, stop;
    hipEventCreate(&start);
    hipEventCreate(&stop);

    hipStream_t stream;
    hipStreamCreateWithFlags(&stream, hipStreamNonBlocking);

    // Copy host memory to device
    hipMemcpyAsync(d_A, h_A, mem_size_A, hipMemcpyHostToDevice, stream);
    hipMemcpyAsync(d_B, h_B, mem_size_B, hipMemcpyHostToDevice, stream);

    // Record the start event
    hipEventRecord(start, stream);

    // Execute the rocBLAS matrix multiplication
    int nIter = 300;

    rocblas_handle handle;
    rocblas_create_handle(&handle);

    const float alpha = 1.0f;
    const float beta = 0.0f;

    for (int j = 0; j < nIter; j++) {
        rocblas_sgemm(handle, rocblas_operation_none, rocblas_operation_none,
                      dimsB.x, dimsA.y, dimsA.x,
                      &alpha, d_B, dimsB.x, d_A, dimsA.x, &beta, d_C, dimsB.x);
    }

    // Record the stop event
    hipEventRecord(stop, stream);
    hipEventSynchronize(stop);

    float msecTotal = 0.0f;
    hipEventElapsedTime(&msecTotal, start, stop);

    // Compute and print the performance
    float msecPerMatrixMul = msecTotal / nIter;
    double flopsPerMatrixMul = 2.0 * static_cast<double>(dimsA.x) *
                               static_cast<double>(dimsA.y) *
                               static_cast<double>(dimsB.x);
    double gigaFlops = (flopsPerMatrixMul * 1.0e-9f) / (msecPerMatrixMul / 1000.0f);
    printf("rocBLAS Performance= %.2f GFlop/s, Time= %.3f msec\n", gigaFlops, msecPerMatrixMul);

    // Copy result from device to host
    hipMemcpyAsync(h_C, d_C, mem_size_C, hipMemcpyDeviceToHost, stream);
    hipStreamSynchronize(stream);

    printf("Checking computed result for correctness: ");
    bool correct = true;
    double eps = 1.e-6;  // machine zero

    for (int i = 0; i < static_cast<int>(dimsC.x * dimsC.y); i++) {
        double abs_err = fabs(h_C[i] - (dimsA.x * valB));
        double abs_val = fabs(h_C[i]);
        double rel_err = abs_err / abs_val;

        if (rel_err > eps) {
            printf("Error! Matrix[%05d]=%.8f, ref=%.8f error term is > %E\n", i, h_C[i], dimsA.x * valB, eps);
            correct = false;
        }
    }

    printf("%s\n", correct ? "Result = PASS" : "Result = FAIL");

    rocblas_destroy_handle(handle);
    hipFree(h_A);
    hipFree(h_B);
    hipFree(h_C);
    hipFree(d_A);
    hipFree(d_B);
    hipFree(d_C);
    hipEventDestroy(start);
    hipEventDestroy(stop);

    return correct ? EXIT_SUCCESS : EXIT_FAILURE;
}

/**
 * Program main
 */
int main(int argc, char **argv) {
    printf("[Matrix Multiply Using rocBLAS] - Starting...\n");

    dim3 dimsA(320, 320, 1);
    dim3 dimsB(320, 320, 1);

    // Width and Height of Matrices A and B can be set via command line arguments
    // Error handling can be added here for more robustness

    printf("MatrixA(%d,%d), MatrixB(%d,%d)\n", dimsA.x, dimsA.y, dimsB.x, dimsB.y);

    hipProfilerStart();
    int matrix_result = MatrixMultiply(argc, argv, dimsA, dimsB);
    hipProfilerStop();

    return matrix_result;
}

```

结果：

```
[Matrix Multiply Using rocBLAS] - Starting...
MatrixA(320,320), MatrixB(320,320)
rocBLAS Performance= 229.47 GFlop/s, Time= 0.286 msec
Checking computed result for correctness: Result = PASS
```


**hipBLAS** 示例代码如下：

```
#include <stdio.h>
#include <assert.h>
#include <hip/hip_runtime.h>
#include <hipblas.h>  

void ConstantInit(float *data, int size, float val) {
    for (int i = 0; i < size; ++i) {
        data[i] = val;
    }
}

int MatrixMultiply(int argc, char **argv, const dim3 &dimsA, const dim3 &dimsB) {
    // Allocate host memory for matrices A and B
    unsigned int size_A = dimsA.x * dimsA.y;
    unsigned int mem_size_A = sizeof(float) * size_A;
    float *h_A = (float*)malloc(mem_size_A);
    unsigned int size_B = dimsB.x * dimsB.y;
    unsigned int mem_size_B = sizeof(float) * size_B;
    float *h_B = (float*)malloc(mem_size_B);

    // Initialize host memory
    const float valB = 0.01f;
    ConstantInit(h_A, size_A, 1.0f);
    ConstantInit(h_B, size_B, valB);

    // Allocate device memory
    float *d_A, *d_B, *d_C;
    dim3 dimsC(dimsB.x, dimsA.y, 1);
    unsigned int mem_size_C = dimsC.x * dimsC.y * sizeof(float);
    float *h_C = (float*)malloc(mem_size_C);

    if (h_C == NULL) {
        fprintf(stderr, "Failed to allocate host matrix C!\n");
        exit(EXIT_FAILURE);
    }

    hipMalloc(&d_A, mem_size_A);
    hipMalloc(&d_B, mem_size_B);
    hipMalloc(&d_C, mem_size_C);

    // Allocate HIP events for timing
    hipEvent_t start, stop;
    hipEventCreate(&start);
    hipEventCreate(&stop);

    hipStream_t stream;
    hipStreamCreateWithFlags(&stream, hipStreamNonBlocking);

    // Copy host memory to device
    hipMemcpyAsync(d_A, h_A, mem_size_A, hipMemcpyHostToDevice, stream);
    hipMemcpyAsync(d_B, h_B, mem_size_B, hipMemcpyHostToDevice, stream);

    // Record the start event
    hipEventRecord(start, stream);

    // Execute the hipBLAS matrix multiplication
    int nIter = 300;

    hipblasHandle_t handle;
    hipblasCreate(&handle);  

    const float alpha = 1.0f;
    const float beta = 0.0f;

    for (int j = 0; j < nIter; j++) {
        hipblasSgemm(handle, HIPBLAS_OP_N, HIPBLAS_OP_N, 
                     dimsB.x, dimsA.y, dimsA.x, 
                     &alpha, d_B, dimsB.x, d_A, dimsA.x, 
                     &beta, d_C, dimsB.x);  
    }

    // Record the stop event
    hipEventRecord(stop, stream);
    hipEventSynchronize(stop);

    float msecTotal = 0.0f;
    hipEventElapsedTime(&msecTotal, start, stop);

    // Compute and print the performance
    float msecPerMatrixMul = msecTotal / nIter;
    double flopsPerMatrixMul = 2.0 * static_cast<double>(dimsA.x) *
                               static_cast<double>(dimsA.y) *
                               static_cast<double>(dimsB.x);
    double gigaFlops = (flopsPerMatrixMul * 1.0e-9f) / (msecPerMatrixMul / 1000.0f);
    printf("hipBLAS Performance= %.2f GFlop/s, Time= %.3f msec\n", gigaFlops, msecPerMatrixMul);

    // Copy result from device to host
    hipMemcpyAsync(h_C, d_C, mem_size_C, hipMemcpyDeviceToHost, stream);
    hipStreamSynchronize(stream);

    printf("Checking computed result for correctness: ");
    bool correct = true;
    double eps = 1.e-6;  // machine zero

    for (int i = 0; i < static_cast<int>(dimsC.x * dimsC.y); i++) {
        double abs_err = fabs(h_C[i] - (dimsA.x * valB));
        double abs_val = fabs(h_C[i]);
        double rel_err = abs_err / abs_val;

        if (rel_err > eps) {
            printf("Error! Matrix[%05d]=%.8f, ref=%.8f error term is > %E\n", i, h_C[i], dimsA.x * valB, eps);
            correct = false;
        }
    }

    printf("%s\n", correct ? "Result = PASS" : "Result = FAIL");

    hipblasDestroy(handle);  
    hipFree(h_A);
    hipFree(h_B);
    hipFree(h_C);
    hipFree(d_A);
    hipFree(d_B);
    hipFree(d_C);
    hipEventDestroy(start);
    hipEventDestroy(stop);

    return correct ? EXIT_SUCCESS : EXIT_FAILURE;
}

int main(int argc, char **argv) {
    printf("[Matrix Multiply Using hipBLAS] - Starting...\n");

    dim3 dimsA(320, 320, 1);
    dim3 dimsB(320, 320, 1);

    printf("MatrixA(%d,%d), MatrixB(%d,%d)\n", dimsA.x, dimsA.y, dimsB.x, dimsB.y);

    hipProfilerStart();
    int matrix_result = MatrixMultiply(argc, argv, dimsA, dimsB);
    hipProfilerStop();

    return matrix_result;
}

```

结果：

```
[Matrix Multiply Using hipBLAS] - Starting...
MatrixA(320,320), MatrixB(320,320)
hipBLAS Performance= 227.54 GFlop/s, Time= 0.288 msec
Checking computed result for correctness: Result = PASS
```

**rocBLAS** 的性能为 229.47 GFLOP/s，运算时间为 0.286 毫秒；**hipBLAS** 的性能为 227.54 GFLOP/s，运算时间为 0.288 毫秒。

从结果上看，**rocBLAS** 和 **hipBLAS** 的性能差距非常小，都达到了 227-229 GFLOP/s 的水平。两者的 API 设计极为相似，这意味着开发人员可以方便地在不同的库之间迁移代码。在性能方面，rocBLAS 和 hipBLAS 的差异并不显著，可能主要与底层实现优化有关。
