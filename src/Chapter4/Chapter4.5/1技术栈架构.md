# 技术栈架构
NVIDIA 平台：基于 CUDA 的技术栈架构高度集成，提供了丰富的硬件加速功能，如 Tensor Cores，以及深度优化的库（cuBLAS、cuDNN、TensorRT），使得 TVM 能够通过多层次优化，充分发挥 NVIDIA GPU 的潜力，适用于大规模深度学习训练和推理任务。

AMD 平台：ROCm 提供了开放的技术栈，结合 HIP 编程模型，使得 TVM 能够在 AMD GPU 上运行。但与 NVIDIA 的专有技术栈相比，AMD 平台的硬件加速支持较少，库优化较为基础，导致 TVM 在 AMD GPU 上的性能表现不如 NVIDIA 平台强劲。AMD 在异构计算和跨平台兼容性方面表现更好，但在深度学习推理任务中，其优化深度仍有待提高。